# Mixture of Recursions (MoR) - Inference Usage Guide

## ğŸš€ Overview

This repository provides comprehensive inference capabilities for the **Mixture of Recursions** model, supporting both local inference and HuggingFace Hub deployment.

## ğŸ“‹ Quick Start Options

### ğŸ  **Local Inference**
Use your locally trained model directly:
```bash
# Interactive chat mode
python vm_scripts/local_inference.py --interactive

# Single prompt
python vm_scripts/local_inference.py --prompt "Your prompt here"

# Comprehensive testing
python comprehensive_inference_test.py
```

### ğŸ¤— **HuggingFace Hub Inference**
Use the model deployed on HuggingFace Hub:
```bash
# Test from HuggingFace
python huggingface_upload/comprehensive_hf_inference_test.py --model-name sudeshmu/mixture-of-recursions-360m
```

## ğŸ“ File Structure

```
mixture_of_recursions/
â”œâ”€â”€ ğŸ“„ INFERENCE_USAGE.md                    # This file
â”œâ”€â”€ ğŸ“„ LOCAL_INFERENCE_README.md             # Local inference guide
â”œâ”€â”€ ğŸ“„ HUGGINGFACE_INFERENCE_README.md       # HuggingFace inference guide
â”œâ”€â”€ ğŸ“„ INFERENCE_TEST_RESULTS.md             # Test results documentation
â”œâ”€â”€ ğŸ§ª comprehensive_inference_test.py       # Local model testing
â”œâ”€â”€ ğŸ§ª test_inference.py                     # Basic local testing
â”œâ”€â”€ ğŸ¤— huggingface_upload/
â”‚   â””â”€â”€ comprehensive_hf_inference_test.py   # HuggingFace model testing
â”œâ”€â”€ ğŸ® vm_scripts/local_inference.py         # Interactive inference
â””â”€â”€ ğŸ“¦ trained_model/                        # Local model files
    â”œâ”€â”€ pytorch_model.bin (499MB)
    â”œâ”€â”€ config.json
    â””â”€â”€ generation_config.json
```

## ğŸ¯ Choose Your Method

| Method | Use Case | Requirements |
|--------|----------|--------------|
| **ğŸ  Local** | Private, fast inference | Local model files |
| **ğŸ¤— HuggingFace** | Cloud access, sharing | Internet connection |

## ğŸ“– Detailed Guides

- **[ğŸ  Local Inference Guide](LOCAL_INFERENCE_README.md)** - Complete local setup and usage
- **[ğŸ¤— HuggingFace Guide](HUGGINGFACE_INFERENCE_README.md)** - Cloud-based inference
- **[ğŸ“Š Test Results](INFERENCE_TEST_RESULTS.md)** - Comprehensive validation results

## âš¡ Quick Test Commands

### Local Model Test:
```bash
# Basic functionality test
python test_inference.py

# Comprehensive 50-test validation
python comprehensive_inference_test.py
```

### HuggingFace Model Test:
```bash
# Test cloud model (replace with your model name)
python huggingface_upload/comprehensive_hf_inference_test.py --model-name YOUR_USERNAME/YOUR_MODEL_NAME
```

## ğŸ”§ Requirements

**Core Dependencies:**
- `torch` - PyTorch framework
- `transformers` - HuggingFace transformers
- `accelerate` - Model loading optimization

**Install:**
```bash
pip install torch transformers accelerate
```

## ğŸ® Interactive Features

Both local and HuggingFace inference support:
- **Interactive chat mode** with conversation memory
- **Custom generation parameters** (temperature, top-p, length)
- **Batch processing** capabilities
- **Comprehensive testing** with 50 diverse prompts

## ğŸ“Š Model Specifications

- **Architecture**: LlamaForCausalLM with MoR enhancements
- **Parameters**: ~362M (361,821,120)
- **Vocabulary**: 49,152 tokens
- **Context Length**: 1,024 tokens
- **Features**: Dynamic recursion, adaptive computation depth

## ğŸ† Validation Status

âœ… **100% Test Success Rate**  
âœ… **50/50 Comprehensive Tests Passed**  
âœ… **Production Ready**  
âœ… **Zero Technical Failures**

## ğŸš€ Get Started

1. **Choose your method**: Local or HuggingFace
2. **Read the specific guide**: See detailed READMEs above
3. **Run tests**: Validate functionality
4. **Start inferencing**: Interactive or programmatic use

---

*For detailed instructions, see the method-specific README files linked above.* 